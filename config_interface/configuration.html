<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Overview &mdash; Marius 0.0.2 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/marius_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sample Files" href="samples.html" />
    <link rel="prev" title="Configuration Interface" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/marius_logo_scaled.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu"> 
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Configuration Interface</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#link-prediction-example">Link Prediction Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#define-the-model">1. Define the model:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-storage-and-dataset">2. Set storage and dataset:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configure-training-and-evaluation">3. Configure training and evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#node-classification-example">Node Classification Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">1. Define the model:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">2. Set storage and dataset:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">3. Configure training and evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#defining-encoder-architectures">Defining Encoder Architectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#advanced-configuration">Advanced Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pipeline">Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="#partition-buffer">Partition Buffer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="samples.html">Sample Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="full_schema.html">Configuration Schema</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocess_datasets/index.html">Datasets and Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../export_and_inference/index.html">Model Export and Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graph_learning/index.html">Graph Learning</a></li>
</ul>


  <!-- <style>
    a.gh-font {
        font-weight: 800;
        color: rgb(160, 45, 45);
    }
    </style> -->
  <p>
  <!-- <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 1000">
    <path
      d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z" />
  </svg> -->
  <a href="https://github.com/marius-team/marius">GitHub</a>
</p>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Marius</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Configuration Interface</a> &raquo;</li>
      <li>Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/config_interface/configuration.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h1>
<p>The configuration interface allows for high-performance training and evaluation of models without need for writing code.</p>
<p>Configuration files are defined in YAML format and are grouped up into four sections:</p>
<ul class="simple">
<li><p>Model: Defines the architecture of the model, neighbor sampling configuration, loss, and optimizer(s)</p></li>
<li><p>Storage: Specifies the input dataset and how to store the graph, features, and embeddings.</p></li>
<li><p>Training: Sets options for the training procedure and hyperparameters. E.g. batch size, negative sampling.</p></li>
<li><p>Evaluation: Sets options for the evaluation procedure (if any). The options here are similar to those in the training section.</p></li>
</ul>
<section id="link-prediction-example">
<h2>Link Prediction Example<a class="headerlink" href="#link-prediction-example" title="Permalink to this headline"></a></h2>
<p>In this example, we show how to define a configuration file for training a <a class="reference internal" href="../examples/config/lp_fb15k237.html"><span class="doc">3-layer GraphSage GNN</span></a> for link prediction on <a class="reference internal" href="../examples/config/lp_fb15k237.html"><span class="doc">fb15k_237</span></a>.</p>
<p>This example assumes that marius has been installed with <span class="xref std std-doc">pip</span> the dataset has been preprocessed with the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">marius_preprocess</span> <span class="pre">--dataset</span> <span class="pre">fb15k_237</span> <span class="pre">--output_dir</span> <span class="pre">/home/data/datasets/fb15k_237/</span></code></p>
<section id="define-the-model">
<h3>1. Define the model:<a class="headerlink" href="#define-the-model" title="Permalink to this headline"></a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
  <span class="nt">encoder</span><span class="p">:</span>
    <span class="nt">train_neighbor_sampling</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ALL</span>
      <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ALL</span>
      <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ALL</span>
    <span class="nt">layers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">EMBEDDING</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

        <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">FEATURE</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">REDUCTION</span>
          <span class="nt">input_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">options</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">LINEAR</span>

      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GNN</span>
          <span class="nt">options</span><span class="p">:</span>
          <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GRAPH_SAGE</span>
          <span class="nt">aggregator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MEAN</span>
          <span class="nt">input_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">init</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GLOROT_NORMAL</span>

      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GNN</span>
          <span class="nt">options</span><span class="p">:</span>
          <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GRAPH_SAGE</span>
          <span class="nt">aggregator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MEAN</span>
          <span class="nt">input_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">init</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GLOROT_NORMAL</span>

      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GNN</span>
          <span class="nt">options</span><span class="p">:</span>
          <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GRAPH_SAGE</span>
          <span class="nt">aggregator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MEAN</span>
          <span class="nt">input_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">init</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GLOROT_NORMAL</span>

  <span class="nt">decoder</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DISTMULT</span>
  <span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SOFTMAX_CE</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">reduction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SUM</span>
  <span class="nt">dense_optimizer</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ADAM</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.01</span>
  <span class="nt">sparse_optimizer</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ADAGRAD</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
</td>
<td><a class="reference internal image-reference" href="../_images/configuration_lp.png"><img alt="../_images/configuration_lp.png" src="../_images/configuration_lp.png" style="width: 700px;" /></a>
</td>
</tr>
</tbody>
</table>
<p>The above model configuration has 5 stages in the encoder section, each stage separated by a <cite>–</cite>. The first stage has 2 layers, one embedding layer with output
dimension 50 and another feature layer with output dimension of 50. The reduction layer in stage 2 takes input the combined vector of dimension
100 and outputs a 50 dimensional vector. It is followed by 3 stages of GNN layers. The output from the encoder is fed to the decoder of type DISMULT.
The loss function being used is SoftmaxCrossEntropy with sum as the reduction method. The dense optimizer is for all model parameters except the node embeddings.
Node embedings are optimized by the sparse optimizer.</p>
</section>
<section id="set-storage-and-dataset">
<h3>2. Set storage and dataset:<a class="headerlink" href="#set-storage-and-dataset" title="Permalink to this headline"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">storage</span><span class="p">:</span>
  <span class="nt">device_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cpu</span>
  <span class="nt">dataset</span><span class="p">:</span>
    <span class="nt">dataset_dir</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/home/data/datasets/fb15k_237/</span>
  <span class="nt">edges</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">dtype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
  <span class="nt">embeddings</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">dtype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
</pre></div>
</div>
<p>The storage configuration provides information on the location and statistics of the pre-processed dataset. It also specfies where
to store the embeddings and edges during training. The <cite>device_type</cite> is set to <cite>cpu</cite> here, <cite>cuda</cite> mode can be used for gpu training.
<cite>DEVICE_MEMORY</cite> in this case states that the embeddings need to stored in cpu memory.</p>
</section>
<section id="configure-training-and-evaluation">
<h3>3. Configure training and evaluation<a class="headerlink" href="#configure-training-and-evaluation" title="Permalink to this headline"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">training</span><span class="p">:</span>
  <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">negative_sampling</span><span class="p">:</span>
    <span class="nt">num_chunks</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
    <span class="nt">negatives_per_positive</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
    <span class="nt">degree_fraction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">filtered</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="nt">num_epochs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
  <span class="nt">pipeline</span><span class="p">:</span>
    <span class="nt">sync</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">epochs_per_shuffle</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">logs_per_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="nt">evaluation</span><span class="p">:</span>
  <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">negative_sampling</span><span class="p">:</span>
    <span class="nt">filtered</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">epochs_per_eval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">pipeline</span><span class="p">:</span>
    <span class="nt">sync</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>The training configuration specifies number of data samples in each batch and the total number of epochs to train the model for.
Marius groups edges into chunks and reuses negative samples within the chunk. <cite>num_chunks`*`negatives_per_positive</cite> negative edges are
sampled for each positive edge. Marius also uses pipelining to overlap data movement with training which introduces bounded staleness
in the system. We can explicitly set sync to true if we want every minibatch to see the latest embeddings.</p>
</section>
</section>
<section id="node-classification-example">
<h2>Node Classification Example<a class="headerlink" href="#node-classification-example" title="Permalink to this headline"></a></h2>
<p>In this example, we show how to define a configuration file for training a <a class="reference internal" href="../examples/config/nc_ogbn_arxiv.html"><span class="doc">3-layer GAT GNN</span></a> for node classification on <a class="reference internal" href="../examples/config/nc_ogbn_arxiv.html"><span class="doc">ogbn_arxiv</span></a>.</p>
<p>This example assumes that marius has been installed with <span class="xref std std-doc">pip</span> the dataset has been preprocessed with the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">marius_preprocess</span> <span class="pre">--dataset</span> <span class="pre">ogbn_arxiv</span> <span class="pre">--output_dir</span> <span class="pre">/home/data/datasets/ogbn_arxiv/</span></code></p>
<section id="id1">
<h3>1. Define the model:<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
  <span class="nt">learning_task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NODE_CLASSIFICATION</span>
  <span class="nt">encoder</span><span class="p">:</span>
    <span class="nt">train_neighbor_sampling</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ALL</span>
    <span class="nt">layers</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">FEATURE</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">128</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
          <span class="nt">init</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GLOROT_NORMAL</span>
      <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GNN</span>
          <span class="nt">options</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GRAPH_SAGE</span>
            <span class="nt">aggregator</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MEAN</span>
          <span class="nt">input_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">128</span>
          <span class="nt">output_dim</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">40</span>
          <span class="nt">bias</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">init</span><span class="p">:</span>
            <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">GLOROT_NORMAL</span>
  <span class="nt">decoder</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NODE</span>
  <span class="nt">loss</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">CROSS_ENTROPY</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">reduction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SUM</span>
  <span class="nt">dense_optimizer</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ADAM</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.01</span>
  <span class="nt">sparse_optimizer</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ADAGRAD</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
</td>
<td><img alt="../_images/configuration_nc.png" src="../_images/configuration_nc.png" />
</td>
</tr>
</tbody>
</table>
<p>The above node classification example has 2 layers in the encoder section, one feature layer and another GNN layer. The number of
training/evaluation sampling layers should be equal to the number of GNN stages in the model. The model has a decoder of type node
classification. The loss function being used is Cross Entropy with sum as the reduction method.</p>
</section>
<section id="id2">
<h3>2. Set storage and dataset:<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">storage</span><span class="p">:</span>
  <span class="nt">device_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cuda</span>
  <span class="nt">dataset</span><span class="p">:</span>
    <span class="nt">dataset_dir</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/home/data/datasets/ogbn_arxiv/</span>
  <span class="nt">edges</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
  <span class="nt">nodes</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
  <span class="nt">features</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
  <span class="nt">embeddings</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span>
    <span class="nt">options</span><span class="p">:</span>
      <span class="nt">dtype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
  <span class="nt">prefetch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">shuffle_input</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">full_graph_evaluation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>The storage configuration here is very similar to the one shown above in Link Prediction.</p>
</section>
<section id="id3">
<h3>3. Configure training and evaluation<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">training</span><span class="p">:</span>
  <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">num_epochs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
  <span class="nt">pipeline</span><span class="p">:</span>
    <span class="nt">sync</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">epochs_per_shuffle</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">logs_per_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">evaluation</span><span class="p">:</span>
  <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">pipeline</span><span class="p">:</span>
    <span class="nt">sync</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">epochs_per_eval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>The above training configuration has specifications for a training batch size of 1000 and total epochs of 5. The <cite>logs_per_epoch</cite> attribute
sets how often to report progres during training. <cite>epochs_per_eval</cite> sets how often to evaluate the model.</p>
</section>
</section>
<section id="defining-encoder-architectures">
<h2>Defining Encoder Architectures<a class="headerlink" href="#defining-encoder-architectures" title="Permalink to this headline"></a></h2>
<p>The interface enables users to define complex model architectures. The layers field can be seen as a double-list, a list of stages wherein
each stage is again a list of layers. We need to ensure that the total output dimension of a stage is equal to the net input dimension of
the next stage. We need to ensure that the following conditions are met while stacking layers of a model,</p>
<ol class="arabic simple">
<li><p>Embedding/Feature layers have only output dimension. The <cite>input_dim</cite> is set to -1 by default</p></li>
<li><p>A Reduction layer can have inputs from multiple layers in the previous stage and has a single output</p></li>
<li><p>The number of training/evaluation sampling layers should be equal to the GNN stages in the model</p></li>
</ol>
</section>
<section id="advanced-configuration">
<h2>Advanced Configuration<a class="headerlink" href="#advanced-configuration" title="Permalink to this headline"></a></h2>
<section id="pipeline">
<h3>Pipeline<a class="headerlink" href="#pipeline" title="Permalink to this headline"></a></h3>
<p>Marius uses pipelining training architecture that can interleave data access, transfer, and computation to achieve high utilization. This
introduces the possibility of a few mini-batches using stale parameters during training. If <cite>sync</cite> is set to true, the training becomes
synchronous and there is no staleness. Below is a sample configuration where the training is async, there is bounded staleness in the system.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
  <span class="nt">sync</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="nt">staleness_bound</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">16</span>
  <span class="nt">batch_host_queue_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">batch_device_queue_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">gradients_device_queue_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">gradients_host_queue_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">batch_loader_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">batch_transfer_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">compute_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">gradient_transfer_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="nt">gradient_update_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/marius_arch.png"><img alt="../_images/marius_arch.png" class="align-center" src="../_images/marius_arch.png" style="width: 700px;" /></a>
<p>Marius follows a 5-staged pipeline architecture, 4 of which are responsible for data movement and the other is for model computation
and in-GPU parameter updates. The <cite>pipeline</cite> field has options for setting thread counts for each of these stages. <cite>staleness_bound</cite>
sets the maximum number of minibatches that can be present in the pipeline at any time. It implies that after a set of node embedding
updates, at most of 16 mini-batches use stale node embeddings.</p>
</section>
<section id="partition-buffer">
<h3>Partition Buffer<a class="headerlink" href="#partition-buffer" title="Permalink to this headline"></a></h3>
<p>One of the storage backends supported for node embeddings is the <cite>PARTITION_BUFFER</cite> mode, where the nodes are bucketed into p partitions
and every edge falls into one of the p^2 buckets. When pre-processed in the partitioned mode, the edges are ordered in a wat that reduces
the number of node-embedding bucket swaps from the buffer.</p>
<p>The following command pre-processes the fb15k_237 dataset into 10 partitions as required by Marius for training in <cite>PARTITION_BUFFER</cite> mode.</p>
<p><code class="docutils literal notranslate"><span class="pre">marius_preprocess</span> <span class="pre">--dataset</span> <span class="pre">fb15k_237</span> <span class="pre">--num_partitions</span> <span class="pre">10</span> <span class="pre">--output_dir</span> <span class="pre">/home/data/datasets/fb15k_237_partitioned/</span></code></p>
<p>Now, we can set the storage backend for node embeddings to <cite>PARTITION_BUFFER</cite> mode</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">embeddings</span><span class="p">:</span>
  <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PARTITION_BUFFER</span>
  <span class="nt">options</span><span class="p">:</span>
    <span class="nt">dtype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">float</span>
    <span class="nt">num_partitions</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
    <span class="nt">buffer_capacity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
    <span class="nt">prefetching</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p><cite>num_partitions</cite> should hold the same value that was earlier supplied to <cite>marius_preprocess</cite>. <cite>buffer_capacity</cite> states the maximum number of
node embedding buckets that can be present in the memory at any given time. Setting <cite>prefetching</cite> enables the system to prefetch partitions
asynchronously leading to reduction in IO wait times and additional memory overheads.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Configuration Interface" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="samples.html" class="btn btn-neutral float-right" title="Sample Files" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
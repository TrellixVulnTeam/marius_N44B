<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Small Scale Link Prediction (FB15K-237) &mdash; Marius 0.0.2 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/marius_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Large Scale Link Prediction (OGB-WikiKG90Mv2)" href="lp_ogb_wikikg90mv2.html" />
    <link rel="prev" title="Configuration Examples" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html">
            <img src="../../_static/marius_logo_scaled.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu"> 
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../build.html">Build and Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_interface/index.html">Configuration Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../preprocess_datasets/index.html">Datasets and Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../export_and_inference/index.html">Model Export and Inference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Configuration Examples</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Small Scale Link Prediction (FB15K-237)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#preprocess-dataset">1. Preprocess Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-configuration-file">2. Define Configuration File</a></li>
<li class="toctree-l4"><a class="reference internal" href="#train-model">3. Train Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#inference">4. Inference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lp_ogb_wikikg90mv2.html">Large Scale Link Prediction (OGB-WikiKG90Mv2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lp_paleobiology.html">Paleobiology Dataset Link Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lp_custom.html">Custom Dataset Link Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="nc_ogbn_arxiv.html">Small Scale Node Classification (OGBN-Arxiv)</a></li>
<li class="toctree-l3"><a class="reference internal" href="nc_ogbn_papers100m.html">Large Scale Node Classification (OGBN-Papers100M)</a></li>
<li class="toctree-l3"><a class="reference internal" href="nc_custom.html">Custom Dataset Node Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/index.html">Python Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../graph_learning/index.html">Graph Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/index.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Debugging and FAQ</a></li>
</ul>


  <!-- <style>
    a.gh-font {
        font-weight: 800;
        color: rgb(160, 45, 45);
    }
    </style> -->
  <p>
  <!-- <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 1000">
    <path
      d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z" />
  </svg> -->
  <a href="https://github.com/marius-team/marius">GitHub</a>
</p>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Marius</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Examples</a> &raquo;</li>
          <li><a href="index.html">Configuration Examples</a> &raquo;</li>
      <li>Small Scale Link Prediction (FB15K-237)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/examples/config/lp_fb15k237.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="small-scale-link-prediction-fb15k-237">
<h1>Small Scale Link Prediction (FB15K-237)<a class="headerlink" href="#small-scale-link-prediction-fb15k-237" title="Permalink to this headline"></a></h1>
<p>In this tutorial, we use the <strong>FB15K_237 knowledge graph</strong> as an example to demonstrate a step-by-step walkthrough from preprocessing the dataset to defining the configuration file and to training <strong>a link prediction model with the DistMult algorithm</strong>.</p>
<section id="preprocess-dataset">
<h2>1. Preprocess Dataset<a class="headerlink" href="#preprocess-dataset" title="Permalink to this headline"></a></h2>
<p>Preprocessing a dataset is straightforward with the <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code> command. This command comes with <code class="docutils literal notranslate"><span class="pre">marius</span></code> when <code class="docutils literal notranslate"><span class="pre">marius</span></code> is installed. See (TODO link) for installation information.</p>
<p>Assuming <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code> has been built, we preprocess the FB15K_237 dataset by running the following command (assuming we are in the <code class="docutils literal notranslate"><span class="pre">marius</span></code> root directory):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ marius_preprocess --dataset fb15k_237 --output_directory datasets/fb15k_237_example/
Downloading FB15K-237.2.zip to datasets/fb15k_237_example/FB15K-237.2.zip
Reading edges
Remapping Edges
Node mapping written to: datasets/fb15k_237_example/nodes/node_mapping.txt
Relation mapping written to: datasets/fb15k_237_example/edges/relation_mapping.txt
Dataset statistics written to: datasets/fb15k_237_example/dataset.yaml
</pre></div>
</div>
<p>The  <code class="docutils literal notranslate"><span class="pre">--dataset</span></code> flag specifies which of the pre-set datasets <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code> will preprocess and download.</p>
<p>The  <code class="docutils literal notranslate"><span class="pre">--output_directory</span></code> flag specifies where the preprocessed graph will be output and is set by the user. In this example, assume we have not created the datasets/fb15k_237_example repository. <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code> will create it for us.</p>
<p>For detailed usages of  <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code>, please refer to <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span> <span class="pre">-h</span></code>.</p>
<p>Let’s check what is inside the created directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ls -l datasets/fb15k_237_example/
dataset.yaml                       <span class="c1"># input dataset statistics</span>
nodes/
  node_mapping.txt                 <span class="c1"># mapping of raw node ids to integer uuids</span>
edges/
  relation_mapping.txt             <span class="c1"># mapping of raw edge(relation) ids to integer uuids</span>
  test_edges.bin                   <span class="c1"># preprocessed testing edge list</span>
  train_edges.bin                  <span class="c1"># preprocessed training edge list</span>
  validation_edges.bin             <span class="c1"># preprocessed validation edge list</span>
train.txt                          <span class="c1"># raw training edge list</span>
test.txt                           <span class="c1"># raw testing edge list</span>
valid.txt                          <span class="c1"># raw validation edge list</span>
text_cvsc.txt                      <span class="c1"># relation triples as used in Toutanova and Chen CVSM-2015</span>
text_emnlp.txt                     <span class="c1"># relation triples as used inToutanova et al. EMNLP-2015</span>
README.txt                         <span class="c1"># README of the downloaded FB15K-237 dataset</span>
</pre></div>
</div>
<p>Let’s check what is inside the generated <code class="docutils literal notranslate"><span class="pre">dataset.yaml</span></code> file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ cat datasets/fb15k_237_example/dataset.yaml
base_directory: /marius-internal/datasets/fb15k_237_example/
num_edges: <span class="m">272115</span>
num_nodes: <span class="m">14541</span>
num_relations: <span class="m">237</span>
num_train: <span class="m">272115</span>
num_valid: <span class="m">17535</span>
num_test: <span class="m">20466</span>
node_feature_dim: -1
rel_feature_dim: -1
num_classes: -1
initialized: <span class="nb">false</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the above <code class="docutils literal notranslate"><span class="pre">marius_preprocess</span></code> command fails due to any missing directory errors, please create the <code class="docutils literal notranslate"><span class="pre">&lt;output_directory&gt;/edges</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;output_directory&gt;/nodes</span></code> directories as a workaround.</p>
</div>
</section>
<section id="define-configuration-file">
<h2>2. Define Configuration File<a class="headerlink" href="#define-configuration-file" title="Permalink to this headline"></a></h2>
<p>To train a model, we need to define a YAML configuration file based on information created from marius_preprocess.</p>
<p>The configuration file contains information including but not limited to the inputs to the model, training procedure, and hyperparameters to optimize. Given a configuration file, marius assembles a model depending on the given parameters. The configuration file is grouped up into four sections:</p>
<ul class="simple">
<li><p>Model: Defines the architecture of the model, neighbor sampling configuration, loss, and optimizer(s)</p></li>
<li><p>Storage: Specifies the input dataset and how to store the graph, features, and embeddings.</p></li>
<li><p>Training: Sets options for the training procedure and hyperparameters. E.g. batch size, negative sampling.</p></li>
<li><p>Evaluation: Sets options for the evaluation procedure (if any). The options here are similar to those in the training section.</p></li>
</ul>
<p>For the full configuration schema, please refer to <code class="docutils literal notranslate"><span class="pre">docs/config_interface</span></code>.</p>
<p>An example YAML configuration file for the FB15K_237 dataset is given in <code class="docutils literal notranslate"><span class="pre">examples/configuration/fb15k_237.yaml</span></code>. Note that the <code class="docutils literal notranslate"><span class="pre">base_directory</span></code> is set to the preprocessing output directory, in our example, <code class="docutils literal notranslate"><span class="pre">datasets/fb15k_237_example/</span></code>.</p>
<p>Let’s create the same YAML configuration file for the FB15K_237 dataset from scratch. We follow the structure of the configuration file and create each of the four sections one by one. In a YAML file, indentation is used to denote nesting and all parameters are in the format of key-value pairs.</p>
<ol class="arabic">
<li><p>First, we define the <strong>model</strong>. We begin by setting all required parameters. This includes <code class="docutils literal notranslate"><span class="pre">learning_task</span></code>, <code class="docutils literal notranslate"><span class="pre">encoder</span></code>, <code class="docutils literal notranslate"><span class="pre">decoder</span></code>, and <code class="docutils literal notranslate"><span class="pre">loss</span></code>. Since we are training a link prediction model, set the <code class="docutils literal notranslate"><span class="pre">learning_task</span></code> to <code class="docutils literal notranslate"><span class="pre">LINK_PREDICTION</span></code>. Since we are training a model with DistMult, set the <code class="docutils literal notranslate"><span class="pre">type</span></code> of <code class="docutils literal notranslate"><span class="pre">decoder</span></code> to <code class="docutils literal notranslate"><span class="pre">DISTMULT</span></code>. We set the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> to be an <code class="docutils literal notranslate"><span class="pre">EMBEDDING</span></code> table with 50-dimensional embeddings. The rest of the configurations can be fine-tuned by the user.</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">learning_task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LINK_PREDICTION</span><span class="w"></span>
<span class="w">  </span><span class="nt">encoder</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">layers</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">EMBEDDING</span><span class="w"></span>
<span class="w">          </span><span class="nt">output_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50</span><span class="w"></span>
<span class="w">  </span><span class="nt">decoder</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">DISTMULT</span><span class="w"></span>
<span class="w">    </span><span class="nt">options</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">input_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50</span><span class="w"></span>
<span class="w">  </span><span class="nt">loss</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SOFTMAX</span><span class="w"></span>
<span class="w">    </span><span class="nt">options</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">reduction</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SUM</span><span class="w"></span>
<span class="w">  </span><span class="nt">dense_optimizer</span><span class="p">:</span><span class="w"> </span><span class="c1"># optimizer to use for dense model parameters. In this case these are the DistMult relation (edge-type) embeddings</span><span class="w"></span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ADAM</span><span class="w"></span>
<span class="w">      </span><span class="nt">options</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span><span class="w"></span>
<span class="w">  </span><span class="nt">sparse_optimizer</span><span class="p">:</span><span class="w"> </span><span class="c1"># optimizer to use for node embedding table</span><span class="w"></span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ADAGRAD</span><span class="w"></span>
<span class="w">      </span><span class="nt">options</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span><span class="w"></span>
<span class="nt">storage</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">training</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">evaluation</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Next, we set the <strong>storage</strong> and <strong>dataset</strong>. We begin by setting all required parameters. This includes <code class="docutils literal notranslate"><span class="pre">dataset</span></code>. Here, the <code class="docutils literal notranslate"><span class="pre">base_directory</span></code> is set to <code class="docutils literal notranslate"><span class="pre">datasets/fb15k_237_example/</span></code>, which is the preprocessing output directory. To populate the <code class="docutils literal notranslate"><span class="pre">num_edges</span></code>, <code class="docutils literal notranslate"><span class="pre">num_train</span></code>,…, <code class="docutils literal notranslate"><span class="pre">num_test</span></code> fields, we use the same input dataset statistics obtained from <code class="docutils literal notranslate"><span class="pre">datasets/fb15k_237_example/dataset.yaml</span></code>.</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">storage</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">device_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cuda</span><span class="w"></span>
<span class="w">  </span><span class="nt">dataset</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">base_directory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">datasets/fb15k_237_example/</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_edges</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">272115</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">272115</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_nodes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">14541</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_relations</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">237</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_valid</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">17535</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_test</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20466</span><span class="w"></span>
<span class="w">  </span><span class="nt">edges</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span><span class="w"></span>
<span class="w">  </span><span class="nt">embeddings</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">DEVICE_MEMORY</span><span class="w"></span>
<span class="w">  </span><span class="nt">save_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="nt">training</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">evaluation</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Lastly, we configure <strong>training</strong> and <strong>evaluation</strong>. We begin by setting all required parameters. This includes <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> and <code class="docutils literal notranslate"><span class="pre">negative_sampling</span></code>. We set <code class="docutils literal notranslate"><span class="pre">num_epochs=10</span></code> (10 epochs to train) to demonstrate this example. Note that <code class="docutils literal notranslate"><span class="pre">negative_sampling</span></code> is required for link prediction.</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">storage</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># omit</span><span class="w"></span>
<span class="nt">training</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span><span class="w"></span>
<span class="w">  </span><span class="nt">negative_sampling</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">num_chunks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"></span>
<span class="w">    </span><span class="nt">negatives_per_positive</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span><span class="w"></span>
<span class="w">    </span><span class="nt">degree_fraction</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"></span>
<span class="w">    </span><span class="nt">filtered</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"></span>
<span class="w">  </span><span class="nt">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"></span>
<span class="w">  </span><span class="nt">pipeline</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">sync</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="w">  </span><span class="nt">epochs_per_shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"></span>
<span class="nt">evaluation</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span><span class="w"></span>
<span class="w">  </span><span class="nt">negative_sampling</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">filtered</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="w">  </span><span class="nt">pipeline</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">sync</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
</section>
<section id="train-model">
<h2>3. Train Model<a class="headerlink" href="#train-model" title="Permalink to this headline"></a></h2>
<p>After defining our configuration file, training is run with <code class="docutils literal notranslate"><span class="pre">marius_train</span> <span class="pre">&lt;your_config.yaml&gt;</span></code>.</p>
<p>We can now train our example using the configuration file we just created by running the following command (assuming we are in the <code class="docutils literal notranslate"><span class="pre">marius</span></code> root directory):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ marius_train datasets/fb15k_237_example/fb15k_237.yaml
 <span class="o">[</span><span class="m">2022</span>-04-03 <span class="m">14</span>:53:15.106<span class="o">]</span> <span class="o">[</span>info<span class="o">]</span> <span class="o">[</span>marius.cpp:45<span class="o">]</span> Start initialization
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.140<span class="o">]</span> Initialization Complete: <span class="m">4</span>.034s
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.147<span class="o">]</span> <span class="c1">################ Starting training epoch 1 ################</span>
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.224<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">28000</span>/272115<span class="o">]</span>, <span class="m">10</span>.29%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.295<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">56000</span>/272115<span class="o">]</span>, <span class="m">20</span>.58%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.369<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">84000</span>/272115<span class="o">]</span>, <span class="m">30</span>.87%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.447<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">112000</span>/272115<span class="o">]</span>, <span class="m">41</span>.16%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.525<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">140000</span>/272115<span class="o">]</span>, <span class="m">51</span>.45%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.603<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">168000</span>/272115<span class="o">]</span>, <span class="m">61</span>.74%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.685<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">196000</span>/272115<span class="o">]</span>, <span class="m">72</span>.03%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.765<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">224000</span>/272115<span class="o">]</span>, <span class="m">82</span>.32%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.851<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">252000</span>/272115<span class="o">]</span>, <span class="m">92</span>.61%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.906<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">272115</span>/272115<span class="o">]</span>, <span class="m">100</span>.00%
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.906<span class="o">]</span> <span class="c1">################ Finished training epoch 1 ################</span>
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.906<span class="o">]</span> Epoch Runtime: 758ms
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.906<span class="o">]</span> Edges per Second: <span class="m">358990</span>.75
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.906<span class="o">]</span> Evaluating validation <span class="nb">set</span>
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.972<span class="o">]</span>
 <span class="o">=================================</span>
 Link Prediction: <span class="m">35070</span> edges evaluated
 Mean Rank: <span class="m">443</span>.786313
 MRR: <span class="m">0</span>.233709
 Hits@1: <span class="m">0</span>.157998
 Hits@3: <span class="m">0</span>.258597
 Hits@5: <span class="m">0</span>.308640
 Hits@10: <span class="m">0</span>.382407
 Hits@50: <span class="m">0</span>.560137
 Hits@100: <span class="m">0</span>.633191
 <span class="o">=================================</span>
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:19.972<span class="o">]</span> Evaluating <span class="nb">test</span> <span class="nb">set</span>
 <span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:20.043<span class="o">]</span>
 <span class="o">=================================</span>
 Link Prediction: <span class="m">40932</span> edges evaluated
 Mean Rank: <span class="m">454</span>.272940
 MRR: <span class="m">0</span>.230645
 Hits@1: <span class="m">0</span>.155282
 Hits@3: <span class="m">0</span>.253103
 Hits@5: <span class="m">0</span>.304065
 Hits@10: <span class="m">0</span>.382073
 Hits@50: <span class="m">0</span>.559758
 Hits@100: <span class="m">0</span>.630192
 <span class="o">=================================</span>
</pre></div>
</div>
<p>After running this configuration for 10 epochs, we should see a result similar to below with a MRR roughly equal to 0.25:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">=================================</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:27.861<span class="o">]</span> <span class="c1">################ Starting training epoch 10 ################</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:27.944<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">28000</span>/272115<span class="o">]</span>, <span class="m">10</span>.29%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.023<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">56000</span>/272115<span class="o">]</span>, <span class="m">20</span>.58%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.115<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">84000</span>/272115<span class="o">]</span>, <span class="m">30</span>.87%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.220<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">112000</span>/272115<span class="o">]</span>, <span class="m">41</span>.16%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.315<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">140000</span>/272115<span class="o">]</span>, <span class="m">51</span>.45%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.410<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">168000</span>/272115<span class="o">]</span>, <span class="m">61</span>.74%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.506<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">196000</span>/272115<span class="o">]</span>, <span class="m">72</span>.03%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.602<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">224000</span>/272115<span class="o">]</span>, <span class="m">82</span>.32%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.699<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">252000</span>/272115<span class="o">]</span>, <span class="m">92</span>.61%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.772<span class="o">]</span> Edges processed: <span class="o">[</span><span class="m">272115</span>/272115<span class="o">]</span>, <span class="m">100</span>.00%
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.772<span class="o">]</span> <span class="c1">################ Finished training epoch 10 ################</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.772<span class="o">]</span> Epoch Runtime: 911ms
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.772<span class="o">]</span> Edges per Second: <span class="m">298699</span>.22
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.772<span class="o">]</span> Evaluating validation <span class="nb">set</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.834<span class="o">]</span>
<span class="o">=================================</span>
Link Prediction: <span class="m">35070</span> edges evaluated
Mean Rank: <span class="m">303</span>.712946
MRR: <span class="m">0</span>.259462
Hits@1: <span class="m">0</span>.173253
Hits@3: <span class="m">0</span>.286570
Hits@5: <span class="m">0</span>.348104
Hits@10: <span class="m">0</span>.434474
Hits@50: <span class="m">0</span>.626775
Hits@100: <span class="m">0</span>.706045
<span class="o">=================================</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.835<span class="o">]</span> Evaluating <span class="nb">test</span> <span class="nb">set</span>
<span class="o">[</span><span class="m">04</span>/03/22 <span class="m">14</span>:53:28.904<span class="o">]</span>
<span class="o">=================================</span>
Link Prediction: <span class="m">40932</span> edges evaluated
Mean Rank: <span class="m">317</span>.841664
MRR: <span class="m">0</span>.255330
Hits@1: <span class="m">0</span>.169794
Hits@3: <span class="m">0</span>.281858
Hits@5: <span class="m">0</span>.341860
Hits@10: <span class="m">0</span>.429859
Hits@50: <span class="m">0</span>.625208
Hits@100: <span class="m">0</span>.703875
<span class="o">=================================</span>
</pre></div>
</div>
<p>Let’s check again what was added in the <code class="docutils literal notranslate"><span class="pre">datasets/fb15k_237_example/</span></code> directory. For clarity, we only list the files that were created in training. Notice that several files have been created, including the trained model, the embedding table, a full configuration file, and output logs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ls datasets/fb15k_237_example/
model.pt                           <span class="c1"># contains the dense model parameters, embeddings of the edge-types</span>
model_state.pt                     <span class="c1"># optimizer state of the trained model parameters</span>
full_config.yaml                   <span class="c1"># detailed config generated based on user-defined config</span>
metadata.csv                       <span class="c1"># information about metadata</span>
logs/                              <span class="c1"># logs containing output, error, debug,  information</span>
nodes/
  embeddings.bin                   <span class="c1"># trained node embeddings of the graph</span>
  embeddings_state.bin             <span class="c1"># node embedding optimizer state</span>
  ...
edges/
  ...
...
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">model.pt</span></code> contains the dense model parameters. For DistMult, this is the embeddings of the edge-types. For GNN encoders, this file will include the GNN parameters.</p>
</div>
</section>
<section id="inference">
<h2>4. Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h2>
<section id="command-line">
<h3>4.1 Command Line<a class="headerlink" href="#command-line" title="Permalink to this headline"></a></h3>
</section>
<section id="load-into-python">
<h3>4.2 Load Into Python<a class="headerlink" href="#load-into-python" title="Permalink to this headline"></a></h3>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Configuration Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lp_ogb_wikikg90mv2.html" class="btn btn-neutral float-right" title="Large Scale Link Prediction (OGB-WikiKG90Mv2)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Custom Dataset Link Prediction &mdash; Marius 0.0.2 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/marius_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Small Scale Node Classification (OGBN-Arxiv)" href="nc_ogbn_arxiv.html" />
    <link rel="prev" title="Large Scale Link Prediction (OGB-WikiKG90Mv2)" href="lp_ogb_wikikg90mv2.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html">
            <img src="../../_static/marius_logo_scaled.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu"> 
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../build.html">Build and Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_interface/index.html">Configuration Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../preprocess_datasets/index.html">Datasets and Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../export_and_inference/index.html">Model Export and Inference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../config/index.html">Configuration Examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Python Examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="lp_fb15k237.html">Small Scale Link Prediction (FB15K-237)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lp_ogb_wikikg90mv2.html">Large Scale Link Prediction (OGB-WikiKG90Mv2)</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Custom Dataset Link Prediction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#create-dataset-class">1. Create Dataset Class</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-model">2. Create Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-dataloader">3. Create Dataloader</a></li>
<li class="toctree-l4"><a class="reference internal" href="#train-model">4. Train Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#inference">5. Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#save-model">6. Save Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nc_ogbn_arxiv.html">Small Scale Node Classification (OGBN-Arxiv)</a></li>
<li class="toctree-l3"><a class="reference internal" href="nc_ogbn_papers100m.html">Large Scale Node Classification (OGBN-Papers100M)</a></li>
<li class="toctree-l3"><a class="reference internal" href="nc_custom.html">Custom Dataset Node Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../graph_learning/index.html">Graph Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/index.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Debugging and FAQ</a></li>
</ul>


  <!-- <style>
    a.gh-font {
        font-weight: 800;
        color: rgb(160, 45, 45);
    }
    </style> -->
  <p>
  <!-- <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 1000">
    <path
      d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z" />
  </svg> -->
  <a href="https://github.com/marius-team/marius">GitHub</a>
</p>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Marius</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Examples</a> &raquo;</li>
          <li><a href="index.html">Python Examples</a> &raquo;</li>
      <li>Custom Dataset Link Prediction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/examples/python/lp_custom.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="custom-dataset-link-prediction">
<h1>Custom Dataset Link Prediction<a class="headerlink" href="#custom-dataset-link-prediction" title="Permalink to this headline"></a></h1>
<p>This example will demonstrate how to use Marius Python API to do a Link
Prediction task on a small scale graph. In this example we will use ogbn-arxiv
graph. Ogbn-arxiv graph is s dataset that is not added in Marius by default. So
we have to write a custom dataset class before we can do the model training. In
this example we will explain both the process of defining a custom dataset class
and how to make a model for link prediction using DistMult. Also it would be
benefical to go through the lp_fb15k_237 example too because both custom and fb15k_237
will have similar model.</p>
<p><em>Example file location: examples/python/custom_lp.py</em></p>
<p>By going through the example we aim you will understand following things:</p>
<ul class="simple">
<li><p>How to use make your own custom dataset class to preprocess data</p></li>
<li><p>How to define a model using the Python APIs and configure it as needed</p></li>
<li><p>How to add different reporting metrics for the accuracy</p></li>
<li><p>How to initialize dataloader objects for training and evaluation</p></li>
<li><p>And lastly how to do training and evaluation</p></li>
</ul>
<p>Note: This is a GPU example and we are setting the device to GPU at the start of the
main using the line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to run CPU based training please change <em>cuda</em> to <em>cpu</em>.</p>
<section id="create-dataset-class">
<h2>1. Create Dataset Class<a class="headerlink" href="#create-dataset-class" title="Permalink to this headline"></a></h2>
<p>The dataset orbn-arxiv is a custom dataset so for that we will need to make a new
dataset class for preprocessing. This new dataset which in the example is called
<code class="docutils literal notranslate"><span class="pre">MYDATASET</span></code> is a child class of the parent class <code class="docutils literal notranslate"><span class="pre">LinkPredictionDataset</span></code>.
Making a new dataset class requires writing two methods:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">download()</span></code>: This method downloads the dataset from the source location and
extracts all the necessary files for preprocessing. In this example we are only
using the <code class="docutils literal notranslate"><span class="pre">raw/edges.csv</span></code>. So in the download method we extract it properly.
We are doing it using the following method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">input_train_edges_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_directory</span> <span class="o">/</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;edge.csv&quot;</span><span class="p">)</span>
<span class="n">download</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_train_edges_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">download</span><span class="p">:</span>
    <span class="n">archive_path</span> <span class="o">=</span> <span class="n">download_url</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_directory</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">)</span>
    <span class="n">extract_file</span><span class="p">(</span><span class="n">archive_path</span><span class="p">,</span> <span class="n">remove_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">extract_file</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_directory</span> <span class="o">/</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;arxiv/raw/edge.csv.gz&quot;</span><span class="p">))</span>
    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_directory</span> <span class="o">/</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;arxiv/raw/edge.csv&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_train_edges_file</span><span class="p">)</span>
</pre></div>
</div>
<p>All that we are doing here is to download the file, extract the edge.csv file
and rename it to ensure that we can easily reference it in the preprocess function.
Note that marius has built in <code class="docutils literal notranslate"><span class="pre">download_url</span></code> and <code class="docutils literal notranslate"><span class="pre">extract_file</span></code> function if
you want to use it.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">preprocess()</span></code>: The main job of this method is to call the <code class="docutils literal notranslate"><span class="pre">convertor()</span></code> function.
Marius supports two types of convertor. First is a torch based convertor and
the other is a spark based convertor. In this example we are only using
<code class="docutils literal notranslate"><span class="pre">TorchEdgeListConverter</span></code>. For more details about both the convertor you can
find the class defination at location <code class="docutils literal notranslate"><span class="pre">src/python/tools/preprocess/convertors</span></code>.
To use the convertor class we need to define an object of convertor class and
after that we can call <code class="docutils literal notranslate"><span class="pre">convertor.convert()</span></code> to generate the preprocessed files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">converter</span> <span class="o">=</span> <span class="n">TorchEdgeListConverter</span>
<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span> <span class="c1"># 80%-train, 10%-validation, 10%-test</span>
<span class="n">converter</span> <span class="o">=</span> <span class="n">converter</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_directory</span><span class="p">,</span>
    <span class="n">train_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_train_edges_file</span><span class="p">,</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="c1"># col 0 is src and col 1 dst node in input csv</span>
    <span class="n">delim</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="c1"># CSV delimitor is &quot;,&quot;</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="n">splits</span><span class="p">,</span> <span class="c1"># Splitting the data in train, valid and test</span>
    <span class="n">remap_ids</span><span class="o">=</span><span class="n">remap_ids</span> <span class="c1"># Remapping the raw entity ids into random integers</span>
<span class="p">)</span>
<span class="k">return</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
</pre></div>
</div>
<p>As shown above in the code, first we are defining a convertor object. There are
many options in convertor object and you can find more details in the class
definition. In this example we are passing following things:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">output_dir=self.output_directory</span></code>: For file output location</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_edges=self.input_train_edges_file</span></code>: Input edges file to preprocess</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">columns</span> <span class="pre">=</span> <span class="pre">[0,1]</span></code>: Specifics which columns in edge.csv are source and destination</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">delim=&quot;,&quot;</span></code>: What delimitor is used in the csv</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">splits</span> <span class="pre">=</span> <span class="pre">splits</span></code>: In this example we only have single edge.csv file so what fractions to split data in train, valid and test</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">remap_ids=remap_ids</span></code>: Remapping the raw entity ids to a random number</p></li>
</ul>
<p>Lastly once the <code class="docutils literal notranslate"><span class="pre">converter.convert()</span></code> is called the input <code class="docutils literal notranslate"><span class="pre">edge.csv</span></code> is then
converted into <code class="docutils literal notranslate"><span class="pre">edges.bin</span></code> file. The file will be located at <code class="docutils literal notranslate"><span class="pre">self.output_directory</span> <span class="pre">/</span> <span class="pre">Path(&quot;edge.csv&quot;)</span></code>.
And Marius uses this file as input.</p>
</li>
</ul>
<p>Once you have defined the class all you need to do is instansiate the base directory
where you will store all the dataset and preprocessed files. And call the download
and preprocess on the objects. As shown in the code.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">base_directory</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;ogbn_arxiv_dataset/&quot;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">MYDATASET</span><span class="p">(</span><span class="n">base_directory</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">base_directory</span> <span class="o">/</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;edges/train_edges.bin&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">preprocess</span><span class="p">()</span>
</pre></div>
</div>
<p>Lastly, note that dataset preprocessing will return a <code class="docutils literal notranslate"><span class="pre">dataset.yaml</span></code> file which
is needed for further tasks, so in the example we are reading it after <code class="docutils literal notranslate"><span class="pre">preprocess()</span></code>.</p>
<p>Once you are done with preprocessing the dataset rest of the steps will be similar
to the lp_fb15k_237 example.</p>
</section>
<section id="create-model">
<h2>2. Create Model<a class="headerlink" href="#create-model" title="Permalink to this headline"></a></h2>
<p>Next step is to define a model for the task. In this example we are going to make
a model with <em>DistMult</em>. The model is defined in the function <code class="docutils literal notranslate"><span class="pre">init_model</span></code>.
There are three steps to defining a model:</p>
<p>1. Defining an encoder: In this example we are defining a single layer encoder.
The layer is an embedding layer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">dimension</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                             <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>To define a model all you need to do is call the <code class="docutils literal notranslate"><span class="pre">GeneralEncoder(..)</span></code> method with all
the layers as shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">encoders</span><span class="o">.</span><span class="n">GeneralEncoder</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[[</span><span class="n">embedding_layer</span><span class="p">]])</span>
</pre></div>
</div>
<p>In this example we are only having a single layer in the encoder but you can have
more than one layer also. (See the node classification example for refer on how to
pass more than one layer to <code class="docutils literal notranslate"><span class="pre">GeneralEncoder(..)</span></code> method)</p>
<p>2. Defining a decoder: In this example we are using <em>DistMult</em> as our decoder so
we are calling the following method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">decoders</span><span class="o">.</span><span class="n">edge</span><span class="o">.</span><span class="n">DistMult</span><span class="p">(</span><span class="n">num_relations</span><span class="o">=</span><span class="n">num_relations</span><span class="p">,</span>
                                      <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                      <span class="n">use_inverse_relations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                                      <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                      <span class="n">decoder_method</span><span class="o">=</span><span class="s2">&quot;corrupt_node&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that we are using decoder_method as <code class="docutils literal notranslate"><span class="pre">corrupt_node</span></code> but there are other
options available. Please refer to API documentation for more details.</p>
<p>3. Defining a loss function: We are using <em>SoftMax</em> in this example. And defining
it is just doing a function call:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">SoftMax</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>There are many other options available for encoder, decoder and loss functions.
Please refer to the API documentation for more details.</p>
<p>In addition to doing the above three tasks, which defines the model, we also need
to provide details regarding which metrics we want to be reported. This is done through
following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reporter</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">LinkPredictionReporter</span><span class="p">()</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">MeanReciprocalRank</span><span class="p">())</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">MeanRank</span><span class="p">())</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">Hitsk</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">Hitsk</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>Notice that you can add multiple metrics.</p>
<p>Once we have defined the encoder, decoder, loss function and the reporter, we can
create a model object using the following method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">reporter</span><span class="p">)</span>
</pre></div>
</div>
<p>And now this model can be passed to during training and evaluation.</p>
<p>Lastly if you want to add an optimizer to the function you can do it as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">.1</span><span class="p">)]</span>
</pre></div>
</div>
</section>
<section id="create-dataloader">
<h2>3. Create Dataloader<a class="headerlink" href="#create-dataloader" title="Permalink to this headline"></a></h2>
<p>After defining the model we need to define two dataloader objects, one for training
and the other for evaluation. Dataloader objects are used to handle all the data
movement required for training. Marius supported different types of storage backends
like complete InMemory, Partition Buffers, Flat_File, etc. Please refer to documentation
and the original paper for more details.</p>
<p>In this example we are using an InMemory storage backend where all the data will reside
in memory. This can be defined using the method <code class="docutils literal notranslate"><span class="pre">tensor_to_file()</span></code>. Do define
a dataloader object we need to do 3 things:</p>
<ul>
<li><p>First is a simple method call to define which objects need to be read:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_edges</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">tensor_from_file</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">train_edges_file</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">dataset_stats</span><span class="o">.</span><span class="n">num_train</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Second for this example we want to use a negative edge sampler so we define it
as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_neg_sampler</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">CorruptNodeNegativeSampler</span><span class="p">(</span><span class="n">num_chunks</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_negatives</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">degree_fraction</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">filtered</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>And last is to make the data loader object itself which will be used during training
to fetch the data and process batches:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">edges</span><span class="o">=</span><span class="n">train_edges</span><span class="p">,</span>
                                     <span class="n">node_embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                     <span class="n">neg_sampler</span><span class="o">=</span><span class="n">train_neg_sampler</span><span class="p">,</span>
                                     <span class="n">learning_task</span><span class="o">=</span><span class="s2">&quot;lp&quot;</span><span class="p">,</span>
                                     <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>Once done with this we have defined the dataloader for training task. Similarly in the
example we also define a dataloader for evaluation.</p>
</section>
<section id="train-model">
<h2>4. Train Model<a class="headerlink" href="#train-model" title="Permalink to this headline"></a></h2>
<p>Now we have everything available to start the training. For training we run multiple
epochs of training and evaluation in this example.</p>
<p>For training all we need is the following function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">):</span>
    <span class="n">dataloader</span><span class="o">.</span><span class="n">initializeBatches</span><span class="p">()</span>

    <span class="k">while</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">hasNextBatch</span><span class="p">():</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">getBatch</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">dataloader</span><span class="o">.</span><span class="n">updateEmbeddingsForBatch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>All we are doing in this function is as follows:</p>
<ul class="simple">
<li><p>Initializing the batches before the start of the epoch</p></li>
<li><p>If there is a next batch available we fetch the next batch</p></li>
<li><p>We train the model on the fetched batch</p></li>
<li><p>And we update the embeddings</p></li>
</ul>
</section>
<section id="inference">
<h2>5. Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h2>
<p>Similar to training the evaluation is also pretty simple can be concluded easily
using the following function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eval_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">):</span>
    <span class="n">dataloader</span><span class="o">.</span><span class="n">initializeBatches</span><span class="p">()</span>

    <span class="k">while</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">hasNextBatch</span><span class="p">():</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">getBatch</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">evaluate_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">reporter</span><span class="o">.</span><span class="n">report</span><span class="p">()</span>
</pre></div>
</div>
<p>The function does the following:</p>
<ul class="simple">
<li><p>Initialize the batches before the start of every epoch</p></li>
<li><p>Load if there is a next batch of data available</p></li>
<li><p>Evaluate the batch</p></li>
<li><p>Once all batches are done report the metrics we defined earlier in reporter</p></li>
</ul>
</section>
<section id="save-model">
<h2>6. Save Model<a class="headerlink" href="#save-model" title="Permalink to this headline"></a></h2>
<p>Work in progress - More details will be added soon</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lp_ogb_wikikg90mv2.html" class="btn btn-neutral float-left" title="Large Scale Link Prediction (OGB-WikiKG90Mv2)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nc_ogbn_arxiv.html" class="btn btn-neutral float-right" title="Small Scale Node Classification (OGBN-Arxiv)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>